import time
import requests
import json
import re
import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
import signaturehelper
from collections import Counter

class NaverShoppingCrawler:
    def __init__(self):
        """ë„¤ì´ë²„ ì‡¼í•‘ API í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.client_id = st.secrets["CLIENT_ID"]
        self.client_secret = st.secrets["CLIENT_SECRET"]
        self.api_key = st.secrets["API_KEY"]
        self.secret_key = st.secrets["SECRET_KEY"]
        self.customer_id = st.secrets["CUSTOMER_ID"]
        self.api_url = "https://openapi.naver.com/v1/search/shop.json"
        self.base_url = 'https://api.naver.com'
        self.csv_file = "brand_list.csv"

    def get_shopping_trend(self, keyword):
        """ë„¤ì´ë²„ ì‡¼í•‘ ì¸ê¸° ìƒí’ˆ í‚¤ì›Œë“œ ë° ëŒ€í‘œ ì¹´í…Œê³ ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
        url = f"{self.api_url}?query={keyword}&display=15&start=1&sort=sim"
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        response = requests.get(url, headers=headers)
        data = response.json()

        top_keyword_list = []
        category_list = []
        for item in data['items']:
            raw_title = item['title']
            clean_title = re.sub(r'<.*?>', '', raw_title)
            top_keyword_list.extend(clean_title.split())
            category = " > ".join(filter(None, [
                item.get('category1'), item.get('category2'), item.get('category3'), item.get('category4')
            ]))
            if category:
                category_list.append(category)
        
        category_counter = Counter(category_list)
        top_category = category_counter.most_common(1)[0][0] if category_counter else None
        
        return top_keyword_list, top_category

    def get_related_keywords(self, keyword):
        """ë„¤ì´ë²„ ê²€ìƒ‰ì—ì„œ ì—°ê´€ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°"""
        search_url = f'https://search.naver.com/search.naver?query={keyword}'
        search_res = requests.get(search_url)
        search_soup = BeautifulSoup(search_res.text, 'html.parser')

        lis = search_soup.select('.keyword')
        related_keywords = [li.select_one('.tit').text.strip() for li in lis if li.select_one('.tit')]
        return related_keywords

    def get_brand_lists(self, keyword):
        """ë„¤ì´ë²„ ì‡¼í•‘ APIì—ì„œ ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ í›„ CSV íŒŒì¼ì— ì €ì¥"""
        url = f"{self.api_url}?query={keyword}&display=100&start=1&sort=sim"
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        response = requests.get(url, headers=headers)
        data = response.json()
        brands = {item.get("brand", "Unknown") for item in data['items'] if item.get("brand")}
        
        if brands:
            df = pd.DataFrame({"Brand": list(brands)})
            df.to_csv(self.csv_file, mode="a", header=not pd.io.common.file_exists(self.csv_file), index=False)
        return list(brands)

    def get_trend_keywords(self, keyword):
        """ë„¤ì´ë²„ ê´‘ê³  APIì—ì„œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°"""
        def get_header(method, uri):
            timestamp = str(round(time.time() * 1000))
            signature = signaturehelper.Signature.generate(timestamp, method, uri, self.secret_key)
            return {
                'Content-Type': 'application/json; charset=UTF-8',
                'X-Timestamp': timestamp,
                'X-API-KEY': self.api_key,
                'X-Customer': str(self.customer_id),
                'X-Signature': signature
            }

        uri = '/keywordstool'
        method = 'GET'
        time.sleep(1)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€

        response = requests.get(
            self.base_url + uri,
            params={
                'siteId': None,
                'biztpId': None,
                'hintKeywords': keyword,
                'event': None,
                'month': None,
                'showDetail': '1'
            },
            headers=get_header(method, uri)
        )

        # ğŸ¯ API ì‘ë‹µì„ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…
        try:
            data = response.json()
            print("âœ… ë„¤ì´ë²„ API ì‘ë‹µ:", data)  # API ì‘ë‹µ í™•ì¸
        except Exception as e:
            print("âŒ API ì‘ë‹µ ì˜¤ë¥˜:", e)
            return []

        keyword_list = data.get('keywordList', [])

        if not keyword_list:
            print("âš ï¸ keywordListê°€ ë¹„ì–´ ìˆìŒ!")
            return []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€

        keywords = []
        for item in keyword_list:
            try:
                rel_keyword = item['relKeyword']
                pc_qc_cnt = int(item.get('monthlyPcQcCnt', '0'))
                mobile_qc_cnt = int(item.get('monthlyMobileQcCnt', '0'))
                keywords.append((rel_keyword, pc_qc_cnt + mobile_qc_cnt))
            except KeyError as e:
                print(f"âŒ KeyError: {e}, item: {item}")  # íŠ¹ì • í‚¤ê°€ ì—†ëŠ” ê²½ìš° ì˜¤ë¥˜ ì¶œë ¥
                continue
            except ValueError as e:
                print(f"âŒ ValueError: {e}, item: {item}")  # ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€
                continue

        return [item[0] for item in sorted(set(keywords), key=lambda x: x[1], reverse=True)[:100]]


    def get_total_keywords(self, keyword):
        """ìµœì¢… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì‡¼í•‘ íŠ¸ë Œë“œ + ì—°ê´€ í‚¤ì›Œë“œ + íŠ¸ë Œë“œ í‚¤ì›Œë“œ + ë¸Œëœë“œ ëª©ë¡)"""
        total_keywords_list, top_category = self.get_shopping_trend(keyword)
        total_keywords_list.extend(self.get_related_keywords(keyword))
        total_keywords_list.extend(self.get_trend_keywords(keyword))
        brands = self.get_brand_lists(keyword)
        return total_keywords_list, brands, top_category

if __name__ == "__main__":
    keyword = st.text_input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    if keyword:
        crawler = NaverShoppingCrawler()
        total_keywords, brands, top_category = crawler.get_total_keywords(keyword)
        st.write("**í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸:**", total_keywords)
        st.write("**ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸:**", brands)
        st.write("**ê°€ì¥ ë§ì´ ë“±ì¥í•œ ì¹´í…Œê³ ë¦¬:**", top_category)
