import os
import urllib.request
import json
import time
import streamlit as st  # âœ… Streamlit Cloudìš© import ì¶”ê°€
from datetime import datetime, timedelta
from collections import Counter
import pandas as pd
import re
import threading
from concurrent.futures import ThreadPoolExecutor
from collect_keywords_cloud import NaverShoppingCrawler

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Streamlit Cloud Secrets ì‚¬ìš©)
CLIENT_ID = st.secrets["CLIENT_ID"]
CLIENT_SECRET = st.secrets["CLIENT_SECRET"]

# ëŒ€í‘œ í‚¤ì›Œë“œ ì‚¬ì „ ìë™ ìƒì„± í•¨ìˆ˜
def generate_category_keywords(keywords):
    category_keywords = {}
    for keyword in keywords:
        base_word = re.sub(r'[^ê°€-í£a-zA-Z]', '', keyword)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        if len(base_word) > 1:
            category = base_word  # ë‹¨ìˆœí™”í•˜ì—¬ ëŒ€í‘œ í‚¤ì›Œë“œ ì„¤ì •
            if category not in category_keywords:
                category_keywords[category] = []
            category_keywords[category].append(keyword)
    return category_keywords

# ë¹ˆë„ ì ìˆ˜ ê³„ì‚°
def calculate_frequency_score(keywords):
    category_keywords = generate_category_keywords(keywords)
    pattern_dict = {category: re.compile('|'.join(map(re.escape, keywords))) for category, keywords in category_keywords.items()}
    category_counts = Counter()
    for keyword in keywords:
        for category, pattern in pattern_dict.items():
            if pattern.search(keyword):
                category_counts[category] += 1
    max_freq = max(category_counts.values()) if category_counts else 1
    return {word: freq / max_freq for word, freq in category_counts.items()}

# ìœ í–‰ì„± ì ìˆ˜ ê³„ì‚° (ë©€í‹°ìŠ¤ë ˆë”© ì ìš©)
def fetch_trend_score(chunk, start_date, end_date):
    url = "https://openapi.naver.com/v1/datalab/search"
    keyword_groups = [{"groupName": kw[:19].strip(), "keywords": [kw.strip()]} for kw in chunk if kw and kw.strip()]
    body = json.dumps({
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": "date",
        "keywordGroups": keyword_groups
    }, ensure_ascii=False).encode("utf-8")

    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", CLIENT_SECRET)
    request.add_header("Content-Type", "application/json")

    scores = {}
    try:
        response = urllib.request.urlopen(request, data=body)
        if response.getcode() == 200:
            result = json.loads(response.read().decode("utf-8"))
            for item in result.get("results", []):
                keyword = item["title"]
                data = item.get("data", [])
                if len(data) < 2:
                    scores[keyword] = 0
                else:
                    recent = data[-1]["ratio"]
                    previous_avg = sum(d["ratio"] for d in data[:-1]) / max(len(data) - 1, 1)
                    scores[keyword] = recent / previous_avg if previous_avg != 0 else 0
    except urllib.error.HTTPError as e:
        print(f"âŒ HTTPError: {e}")
    return scores

def calculate_trend_scores(keywords):
    end_date = datetime.today().strftime("%Y-%m-%d")
    start_date = (datetime.today() - timedelta(days=30)).strftime("%Y-%m-%d")
    chunk_size = 5
    scores = {}
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(fetch_trend_score, keywords[i:i + chunk_size], start_date, end_date) for i in range(0, len(keywords), chunk_size)]
        for future in futures:
            scores.update(future.result())
    return scores

# í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculator(keyword, crawler, max_keywords=15):
    keywords = crawler.get_total_keywords(keyword)
    frequency_scores = calculate_frequency_score(keywords)
    trend_scores = calculate_trend_scores(list(frequency_scores.keys()))
    scores = []
    for kw in frequency_scores.keys():
        scores.append({
            "í‚¤ì›Œë“œ": kw,
            "ë¹ˆë„ ì ìˆ˜": frequency_scores.get(kw, 0),
            "ìœ í–‰ì„± ì ìˆ˜": trend_scores.get(kw, 0),
            "ì´ì ": frequency_scores.get(kw, 0) + trend_scores.get(kw, 0),
        })
    return sorted(scores, key=lambda x: x["ì´ì "], reverse=True)[:max_keywords]

# ì‹¤í–‰
if __name__ == "__main__":
    keyword = input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    crawler = NaverShoppingCrawler()
    sorted_scores = calculator(keyword, crawler)
    print("ğŸ“¢ ìƒí’ˆëª…ì— ì í•©í•œ í‚¤ì›Œë“œ:")
    for idx, score in enumerate(sorted_scores, start=1):
        print(f"""{idx}. í‚¤ì›Œë“œ: {score['í‚¤ì›Œë“œ']}, 
        ë¹ˆë„ ì ìˆ˜: {score['ë¹ˆë„ ì ìˆ˜']:.2f}, 
        ìœ í–‰ì„± ì ìˆ˜: {score['ìœ í–‰ì„± ì ìˆ˜']:.2f}, 
        ì´í•© ì ìˆ˜: {score['ì´ì ']:.2f}""")
