import os
import pandas as pd
from datetime import datetime, timedelta
import urllib.request
import json
import time
from collect_keywords import NaverShoppingCrawler
from collections import Counter

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ

CLIENT_ID = st.secrets['CLIENT_ID']
CLIENT_SECRET = st.secrets['CLIENT_SECRET']

if not CLIENT_ID or not CLIENT_SECRET:
    raise ValueError("ğŸš¨ í™˜ê²½ ë³€ìˆ˜ CLIENT_ID ë˜ëŠ” CLIENT_SECRETì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë¹ˆë„ ì ìˆ˜ ê³„ì‚° (NaN ë°©ì§€)
def calculate_frequency_score(keywords):
    keyword_counts = pd.Series(keywords).value_counts()

    if keyword_counts.empty:
        return {kw: 0 for kw in keywords}

    total_count = keyword_counts.sum()  # ì „ì²´ í‚¤ì›Œë“œ ê°œìˆ˜
    keyword_scores = keyword_counts / total_count  # ê° í‚¤ì›Œë“œì˜ ë¹ˆë„ë¥¼ ì „ì²´ ê°œìˆ˜ë¡œ ë‚˜ëˆ  ì •ê·œí™”

    return keyword_scores.to_dict()

# ìœ í–‰ì„± ì ìˆ˜ ê³„ì‚° (í•œ ë²ˆì— 5ê°œì”© ìš”ì²­)
def calculate_trend_scores(keywords):
    end_date = datetime.today().strftime("%Y-%m-%d")
    start_date = (datetime.today() - timedelta(days=30)).strftime("%Y-%m-%d")

    url = "https://openapi.naver.com/v1/datalab/search"
    chunk_size = 5  # 5ê°œì”© ìš”ì²­
    scores = {}

    for i in range(0, len(keywords), chunk_size):
        keyword_chunk = keywords[i:i + chunk_size]

        keyword_groups = [{"groupName": kw[:19].strip(), "keywords": [kw.strip()]} for kw in keyword_chunk if kw and kw.strip()]

        body = {
            "startDate": start_date,
            "endDate": end_date,
            "timeUnit": "date",
            "keywordGroups": keyword_groups
        }

        body = json.dumps(body, ensure_ascii=False).encode("utf-8")

        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", CLIENT_SECRET)
        request.add_header("Content-Type", "application/json")

        try:
            response = urllib.request.urlopen(request, data=body)
            if response.getcode() == 200:
                result = json.loads(response.read().decode("utf-8"))

                for item in result.get("results", []):
                    keyword = item["title"]
                    data = item.get("data", [])
                    if len(data) < 2:
                        scores[keyword] = 0
                    else:
                        recent = data[-1]["ratio"]
                        previous_avg = sum(d["ratio"] for d in data[:-1]) / max(len(data) - 1, 1)
                        scores[keyword] = recent / previous_avg if previous_avg != 0 else 0

            time.sleep(1.5)  # ìš”ì²­ ê°„ê²© ì¡°ì •

        except urllib.error.HTTPError as e:
            error_response = e.read().decode("utf-8")
            print(f"âŒ HTTPError: {e}\nğŸ›‘ API ì—ëŸ¬ ì‘ë‹µ: {error_response}")

    return scores

# í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
def calculator(keyword, crawler, max_keywords=15):
    """ê° í•­ëª©ì˜ ì ìˆ˜ ê³„ì‚°ê¸°"""
    raw_keywords = set(crawler.get_nobrand_keywords(keyword))

    # í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ê¸°ì¤€ ì •ë ¬ (íŠ¸ë Œë“œ í‚¤ì›Œë“œì™€ êµì§‘í•© í•„í„°ë§)
    keywords_with_trend = set(crawler.get_trend_keywords(keyword))
    filtered_keywords = list(raw_keywords & keywords_with_trend)[:max_keywords]

    # ì ìˆ˜ ê³„ì‚°
    trend_scores = calculate_trend_scores(filtered_keywords)
    frequency_scores = calculate_frequency_score(filtered_keywords)

    # ê²°ê³¼ í•©ì‚° ë° ì €ì¥
    scores = []
    for kw in filtered_keywords:
        frequency_score = frequency_scores.get(kw, 0)
        trend_score = trend_scores.get(kw, 0)
        total_score = frequency_score + trend_score

        scores.append({
            "í‚¤ì›Œë“œ": kw,
            "ë¹ˆë„ ì ìˆ˜": frequency_score,
            "ìœ í–‰ì„± ì ìˆ˜": trend_score,
            "ì´ì ": total_score,
        })

    # ì ìˆ˜ ì´í•© ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ 10ê°œ í•­ëª© ì„ íƒ
    sorted_scores = sorted(scores, key=lambda x: x["ì´ì "], reverse=True)[:10]

    return sorted_scores

# ì‹¤í–‰
if __name__ == "__main__":
    keyword = input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    crawler = NaverShoppingCrawler()
    sorted_scores = calculator(keyword, crawler)

    # ğŸ”¥ í¬ë¡¤ëŸ¬ ì¢…ë£Œ (ë©”ëª¨ë¦¬ ì ˆì•½)
    crawler.quit()

    # ì ìˆ˜ ì¶œë ¥
    print("ğŸ“¢ ìƒí’ˆëª…ì— ì í•©í•œ í‚¤ì›Œë“œ:")
    for idx, score in enumerate(sorted_scores, start=1):
        print(f"""{idx}. í‚¤ì›Œë“œ: {score['í‚¤ì›Œë“œ']}, 
        ë¹ˆë„ ì ìˆ˜: {score['ë¹ˆë„ ì ìˆ˜']:.2f}, 
        ìœ í–‰ì„± ì ìˆ˜: {score['ìœ í–‰ì„± ì ìˆ˜']:.2f}, 
        ì´í•© ì ìˆ˜: {score['ì´ì ']:.2f}""")
